Project Sentinel: Political Intelligence PlatformProject Sentinel is a comprehensive, self-hosted platform for the automated ingestion, analysis, and visualization of political and legislative documents.This platform leverages a suite of modern, open-source tools to create a powerful analytical engine. It uses a multi-agent AI system to process documents, build a knowledge graph of the relationships between political entities, and provide data-driven insights into the political landscape.Core FeaturesAutomated Document Ingestion: A configurable crawler service to fetch documents from government websites and other specified sources.AI-Powered Analysis: A multi-agent system built with Python to perform entity extraction, topic modeling, and relationship mapping.Knowledge Graph Backend: Uses Neo4j to store and query the complex relationships between legislators, bills, committees, and topics.Multi-Modal Database: Leverages PostgreSQL with pgvector for relational data and semantic search capabilities.Self-Hosted AI: Powered by LocalAI and Ollama, ensuring data privacy and no reliance on third-party inference APIs.Interactive Frontend: A Next.js application provides a user-friendly interface for initiating ingestion jobs, querying the knowledge graph, and managing the system.Comprehensive Stack: The entire platform is containerized with Docker and orchestrated with Docker Compose for easy deployment and management.Getting StartedPrerequisitesDocker and Docker ComposeA .env file (see .env.example)Local AI models downloaded for LocalAI/Ollama (optional, can be done via their APIs)1. Configure Your EnvironmentCopy the .env.example file to a new file named .env and fill in the required values for your database passwords and any API keys you wish to use.cp .env.example .env
# Now, edit the .env file with your secrets
2. Launch the StackThis project uses a Makefile to simplify Docker Compose commands.# To build and start all services in the background:
make up

# To monitor the logs of all services:
make logs

# To stop all services:
make stop

# To stop and remove all containers, networks, and data volumes (USE WITH CAUTION):
make nuke
3. Accessing ServicesOnce the stack is running, you can access the various components:Main Application UI: http://localhost:3000 (Routed through Kong)Kong API Gateway: http://localhost:8000Neo4j Browser: http://localhost:7474Grafana Dashboards: http://localhost:3001OpenWebUI: http://localhost:8090n8n Workflows: http://localhost:5678MinIO S3 Console: http://localhost:9001Project Structure/agentic_kg: The core Python FastAPI service containing the AI agent logic./crawler: The Python FastAPI service responsible for fetching documents./frontend: The Next.js user interface./init_db: SQL scripts for initializing the PostgreSQL database./kong: Declarative configuration for the API gateway./n8n: JSON definitions for n8n workflows.docker-compose.yml: Defines all the services in the stack.Makefile: Provides helper commands for managing the project.
